{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XDIkbORn8kOM"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kJ6ssXaGJfGN"
   },
   "source": [
    "# Python Data Analysis (Notebook Project)\n",
    "\n",
    "## Overview\n",
    "This notebook showcases Python fundamentals used in data analysis workflows, including:\n",
    "- Reading CSV data with pandas\n",
    "- Input validation and basic data quality checks\n",
    "- Filtering by date ranges and computing summary statistics (mean/min/max)\n",
    "\n",
    "## Datasets\n",
    "This project references two datasets:\n",
    "- `15 Years Stock Data of NVDA AAPL MSFT GOOGL and AMZN.csv`\n",
    "- `USA_Housing.csv`\n",
    "\n",
    "> Note: If you publish this repo publicly, ensure datasets do not contain private or restricted information.  \n",
    "> If the original datasets are not shareable, include a small sample dataset or instructions to obtain the data.\n",
    "\n",
    "## How to run\n",
    "1. Create a Python environment (Python 3.9+ recommended)\n",
    "2. Install dependencies: `pip install -r requirements.txt`\n",
    "3. Open and run: `analysis.ipynb`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "37dgfub0Wbt_",
    "outputId": "6b6ca31f-c3a6-49d0-a387-9a4ccfdbc942"
   },
   "outputs": [],
   "source": [
    "# Stock column selection (non-interactive, portfolio-friendly)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('15 Years Stock Data of NVDA AAPL MSFT GOOGL and AMZN.csv')\n",
    "\n",
    "# Choose what to analyze (edit these two lines if you want a different view)\n",
    "stock_name = 'NVDA'          # options: NVDA, AAPL, MSFT, GOOGL, AMZN\n",
    "price_type = 'Close'         # options: Open, Close, Low, High\n",
    "\n",
    "column = f\"{price_type}_{stock_name}\"\n",
    "\n",
    "# Basic validation (keeps the notebook reproducible without input prompts)\n",
    "if column not in df.columns:\n",
    "    raise ValueError(f\"Column '{column}' not found. Available columns include: {', '.join([c for c in df.columns if c.endswith('_'+stock_name)])}\")\n",
    "\n",
    "if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "    raise TypeError(f\"Column '{column}' must be numeric.\")\n",
    "\n",
    "print(f\"Selected column: {column}\")\n",
    "df[[column]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CXJxi2Ozo_ri"
   },
   "source": [
    "**b)**  **[10 pts]** In this question you are supposed to use an LLM tool to prepare the solution of the same question as Question 1.a.  \n",
    "\n",
    "**Notes:**  \n",
    "* You may need to do some modifications if the code generated by the LLM tool does not produce the desired output.  \n",
    "* In order to get a full point the code must generate the output with exactly the same format and must calculate the output correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GsJ4qNakpDQ6",
    "outputId": "fbb09f49-95d5-4ceb-c3ae-eba5bddad312"
   },
   "outputs": [],
   "source": [
    "# Stock analysis over a date range (non-interactive)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv('15 Years Stock Data of NVDA AAPL MSFT GOOGL and AMZN.csv')\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "\n",
    "# Choose parameters (edit these if you want different results)\n",
    "stock = 'AAPL'              # NVDA, AAPL, MSFT, GOOGL, AMZN\n",
    "price = 'Close'             # Open, Close, Low, High\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2020-12-31'\n",
    "\n",
    "column = f\"{price}_{stock}\"\n",
    "\n",
    "# Validate choices\n",
    "if column not in df.columns or not pd.api.types.is_numeric_dtype(df[column]):\n",
    "    raise ValueError(f\"'{column}' is invalid. Check your stock/price selection.\")\n",
    "\n",
    "# Filter by date range\n",
    "start_date = pd.to_datetime(start_date)\n",
    "end_date = pd.to_datetime(end_date)\n",
    "\n",
    "filtered = df[(df['Date'] >= start_date) & (df['Date'] <= end_date)]\n",
    "\n",
    "if filtered.empty:\n",
    "    raise ValueError(\"No rows found for the selected date range.\")\n",
    "\n",
    "# Summary stats\n",
    "summary = {\n",
    "    \"column\": column,\n",
    "    \"start_date\": str(start_date.date()),\n",
    "    \"end_date\": str(end_date.date()),\n",
    "    \"rows\": int(len(filtered)),\n",
    "    \"min\": float(filtered[column].min()),\n",
    "    \"max\": float(filtered[column].max()),\n",
    "    \"mean\": float(filtered[column].mean()),\n",
    "}\n",
    "\n",
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4Mo0dIYsZtEp"
   },
   "outputs": [],
   "source": [
    "#WHICH LLM TOOL DID YOU USE? WRITE THE NAME OF THE TOOL BELOW\n",
    "\n",
    "ChatGPT is the LLM tool used to generate the code for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ebhyP02PXYz_"
   },
   "source": [
    "**c) [10 pts]** In this question your have to compare the source codes you have provided in Question 1.a and 1.b by mentioning the following aspects:  \n",
    "*   Which source code works faster? Why?\n",
    "*   Which source code looks like more understandable by a Teaching Assistant? Why?  \n",
    "*   Which source code is shorter (ignoring the empty lines)? How do you think that this impacts readibility and execution time of the program?  \n",
    "*   What kind of an improvement(s) would you do on your code in Question 1.a? And in which aspect would it/them improve your code?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8n8i8sPxZVxv"
   },
   "outputs": [],
   "source": [
    "#WRITE YOUR ANSWER HERE\n",
    "\n",
    "#Which source code works faster? Why?\n",
    "\n",
    "I think both code would work similarly as they both use the Pandas library to process the data.\n",
    "If there is a difference in speed between the code it would likely be very marginal. The main difference we would see\n",
    "between the code would be from the input from the user and how the input validation loops would manage the Pandas operation. My code utilizes if/elif while the other uses a getattr function.\n",
    "\n",
    "\n",
    "#Which source code looks like more understandable by a Teaching Assistant? Why?\n",
    "\n",
    "I would say both are pretty understandable but the human code would be more understandable for a Teaching Assistant as it is more broken down and consistent compared to the LLM code.\n",
    "My code uses explicit if/elif/else statements while the LLM code uses getattr(filtered) which may not be as explicit or commonly understandable for beginner programmers. My code also has\n",
    "a very clear structure to the input validation from user which would re-prompt when invalid. The LLM's break function may be less obvious to read. Another example would be the calculation.\n",
    "I have broken down the calculation of each selection calculation type while the LLM's code creates a function for the calculation type and input into one and then includes that varible into the\n",
    "filter and calculate. LLM reduces the lines of code needed and compiles the function more compared to my code. Thus, I would say my code is more understandable since it is not compiles and more\n",
    "broken down.\n",
    "\n",
    "#Which source code is shorter (ignoring the empty lines)? How do you think that this impacts readibility and execution time of the program?\n",
    "\n",
    "Both programs are relatively the same size with the LLM using 2 fewer line but also 531 fewer characters to operate. I dont think this would impact the execution time of the program as much but\n",
    "it does highly improve the readability. With similar number of lines and fewer words, the LLM code has compressed the code to execute the same function and uses complex commands which reduced\n",
    "and cleaned up the code compared to mine.\n",
    "\n",
    "#What kind of an improvement(s) would you do on your code in Question 1.a? And in which aspect would it/them improve your code?\n",
    "\n",
    "One possible improvement I could make would be to create a encapsulated input validation function for each stage of the input. This would make it more fluent to read, test as well as improve\n",
    "by myself or others reading my code. This also breaks down the script and allows more flow in the program. Another example could be to define the input selections prior ot rather than using strings and then validating\n",
    "the string with the database column to confirm valid input. By defining, we would improve the code and prepare it for future use such as additions, subtractions, etc.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ykPO8lAcazKV"
   },
   "source": [
    "*****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GEYuQ9X455W2"
   },
   "source": [
    "### **Question 2  [50 pts]**:\n",
    "\n",
    "In this question you will be doing a simple **Real Estate Analyzer** with the 'USA Housing' real estate dateset.\n",
    "\n",
    "You can download the dataset  \n",
    "Link: https://www.kaggle.com/datasets/vedavyasv/usa-housing\n",
    "\n",
    "Here is a list of tasks to be done **before** answering the questions:  \n",
    "1.   Download the dataset\n",
    "2.   If it is downloaded as an archieve file, then you need to decompress it (the file name will be \"USA_Housing.csv\")\n",
    "3.   Upload the filed to your Colab drive under `/content` folder\n",
    "\n",
    "\n",
    "**a)**  **[30 pts]**  Write code to ask the following questions to the user and get the answers:  \n",
    "1. __Which feature do you want to analyze?:__\n",
    "\n",
    "  * _Options: `'Avg. Area Income'`, `'Avg. Area House Age'`, `'Avg. Area Number of Rooms'`, `'Avg. Area Number of Bedrooms'`, `'Area Population'`, `'Price'`_\n",
    "\n",
    "2. __Enter the minimum threshold value (filter data where feature ≥ this value):__\n",
    "\n",
    "3. __Enter the maximum threshold value (filter data where feature ≤ this value):__\n",
    "\n",
    "4. __Choose calculation type (__`'avg'`, `'min'`, `'max'`, `'count'`__):__\n",
    "\n",
    "\n",
    "__Program Logic:__\n",
    "\n",
    "* Read `USA_Housing.csv`.\n",
    "* Filter rows where the selected feature is between the min and max thresholds.\n",
    "* Compute the requested calculation (avg, min, max, or count).\n",
    "* Display the result in a readable format.\n",
    "\n",
    "__Error Handling Required:__\n",
    "\n",
    "* If the file is missing → Print: `\"Error: File not found. Please check the path.\"`\n",
    "* If no data matches the filters → Print: `\"No records match your criteria.\"`\n",
    "* If an invalid feature is entered → Prompt again until valid.\n",
    "\n",
    "__Example Output:__\n",
    "\n",
    "\n",
    "`Which feature to analyze? (Avg. Area Income / Avg. Area House Age / Avg. Area Number of Rooms / Avg. Area Number of Bedrooms / Area Population / Price):` __Price__\n",
    "\n",
    "`Enter minimum threshold:` __500000__\n",
    "\n",
    "`Enter maximum threshold:` __1000000__\n",
    "\n",
    "`Choose calculation (avg/min/max/count):` __avg__  \n",
    "\n",
    "The average house price between \\$500,000 and \\$1,000,000 is __\\$734,621.__\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cJMg2sDOICnt",
    "outputId": "37753187-fcac-4288-a9d8-64601f9a8f02"
   },
   "outputs": [],
   "source": [
    "# USA Housing: metric on a numeric column within a range (non-interactive)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('USA_Housing.csv')\n",
    "\n",
    "# Choose parameters (edit these)\n",
    "column = 'Price'       # try: 'Price', 'Area Population', etc. (must be numeric)\n",
    "min_amount = 200000\n",
    "max_amount = 800000\n",
    "calc_type = 'mean'     # options: mean, count, min, max\n",
    "\n",
    "# Validate\n",
    "if column not in df.columns:\n",
    "    raise ValueError(f\"'{column}' is not a valid column name. Columns: {list(df.columns)}\")\n",
    "\n",
    "if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "    raise TypeError(f\"Column '{column}' must be numeric.\")\n",
    "\n",
    "if max_amount < min_amount:\n",
    "    raise ValueError(\"max_amount must be >= min_amount.\")\n",
    "\n",
    "if calc_type not in {'mean', 'count', 'min', 'max'}:\n",
    "    raise ValueError(\"calc_type must be one of: mean, count, min, max\")\n",
    "\n",
    "filtered = df[(df[column] >= min_amount) & (df[column] <= max_amount)]\n",
    "\n",
    "result = getattr(filtered[column], calc_type)()\n",
    "\n",
    "print(f\"The {calc_type} of '{column}' between {min_amount} and {max_amount} is {result}\")\n",
    "filtered[[column]].head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "86J1Q8uGIDaw"
   },
   "source": [
    "**b)**  **[10 pts]** Use an LLM tool of your choice to prepare the solution of the same question as Question 2.a.  \n",
    "\n",
    "**Notes:**  \n",
    "* You may need to do some modifications if the code generated by the LLM tool does not produce the desired output.  \n",
    "* In order to get a full point the code must generate the output with exactly the same format and must calculate the output correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 350
    },
    "id": "ZABkwcisIo3m",
    "outputId": "51d4a6a9-1cd8-4307-c2e6-5adbfccbd9a1"
   },
   "outputs": [],
   "source": [
    "# Reusable helper: range-based calculation (no input prompts)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "def range_calculation(df: pd.DataFrame, column: str, min_amount: float, max_amount: float, calc_type: str):\n",
    "    \"\"\"Return a calculation (mean/count/min/max) for values in `column` that fall within [min_amount, max_amount].\"\"\"\n",
    "    if column not in df.columns:\n",
    "        raise ValueError(f\"Column '{column}' not found.\")\n",
    "    if not pd.api.types.is_numeric_dtype(df[column]):\n",
    "        raise TypeError(f\"Column '{column}' must be numeric.\")\n",
    "    if max_amount < min_amount:\n",
    "        raise ValueError(\"max_amount must be >= min_amount.\")\n",
    "    if calc_type not in {'mean', 'count', 'min', 'max'}:\n",
    "        raise ValueError(\"calc_type must be one of: mean, count, min, max\")\n",
    "\n",
    "    filtered = df[(df[column] >= min_amount) & (df[column] <= max_amount)]\n",
    "    return getattr(filtered[column], calc_type)()\n",
    "\n",
    "# Example usage (works with the df from the cell above)\n",
    "example_value = range_calculation(df, column='Price', min_amount=200000, max_amount=800000, calc_type='mean')\n",
    "print(\"Example (mean Price in range):\", example_value)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5X3rvRChaKJ4"
   },
   "outputs": [],
   "source": [
    "#WHICH LLM TOOL DID YOU USE? WRITE THE NAME OF THE TOOL BELOW\n",
    "\n",
    "Google Gemini is the LLM tool used to generate the code for this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "It3YUC8fItHg"
   },
   "source": [
    "**c) [10 pts]** In this question your have to compare the source codes you have provided in Question 2.a and 2.b by mentioning the following aspects:  \n",
    "*  Does it produce the same output for given test cases?\n",
    "*  Does either version handle unexpected inputs / edge cases better (e.g., invalid dates, empty files)?\n",
    "\n",
    "*  Did the LLM introduce techniques you had not considered? If so, explain in detail.\n",
    "*  Which version is easier to debug or modify? Why?  \n",
    "*  What would you take from the LLM’s solution for future work? And in which aspect would it improve your code?\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P-T7go-_Kz3s"
   },
   "outputs": [],
   "source": [
    "#WRITE YOUR ANSWER HERE\n",
    "\n",
    "#Does it produce the same output for given test cases?\n",
    "\n",
    "Yes both versions produce the same output.\n",
    "\n",
    "#Does either version handle unexpected inputs / edge cases better (e.g., invalid dates, empty files)?\n",
    "\n",
    "Both versions handle non-existent column names, alphabetical input in a numeric specific input and validation of calc type. In terms of dates and empty files, if the code is not able to generate, it would generate an error, EmptyDataError.\n",
    "\n",
    "#Did the LLM introduce techniques you had not considered? If so, explain in detail.\n",
    "\n",
    "LLM uses dynamic method calling using getattr(). My code uses simple if/elif. The dynamic method calling reduces the repetitive use of if/elif for the calculations. It also makes it cleaner as you would just add the new calculation\n",
    "to valid_calculations instead of a block of if/elif.\n",
    "\n",
    "#Which version is easier to debug or modify? Why?\n",
    "\n",
    "LLM is easier to debug. The functions are isolated compared to the my code. This way, if there is an issue with how the input is handled, we would know exactly where to look. My code has the input validation all within the main script\n",
    "and would require more time to edit. Moreover, having them isolated is easier to maintain in case of modifications since the code is already isolated, and only require edit to the isolated function to add, remove or modify anything.\n",
    "\n",
    "#What would you take from the LLM’s solution for future work? And in which aspect would it improve your code?\n",
    "\n",
    "I would take one takeaway which would improve the way I code as well as read code and that would be encapsulating logical units. I am noticing that encapsulating logical units help in numerous ways, such as seperating\n",
    "logical code from the main script, highly editable and reusable, more organized, easier to debug errors, etc. It allows the reader and any team memebers to easily follow along with the code as well as future proofs the work\n",
    "in case changes or additions need to be made.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jPrZqSxgSWNr"
   },
   "source": [
    "*****\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DozvI-V26MCm"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rtC6fqdFNkdO"
   },
   "source": [
    "#### This is the end of assignment 1\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "rtC6fqdFNkdO"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "nteract": {
   "version": "0.28.0"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
